{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So46UxSWNzA8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gle0KnkEVug7"
   },
   "outputs": [],
   "source": [
    "file_path = '/content/drive/MyDrive/Colab Notebooks/VICCI/data/generated_train_data.json'\n",
    "training_data = None\n",
    "with open(file_path, 'r') as file:\n",
    "    training_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAU5_s1mM7CG"
   },
   "outputs": [],
   "source": [
    "queries, intents = [], []\n",
    "for train_set in training_data:\n",
    "    for query in train_set['query']:\n",
    "        queries.append(query)\n",
    "        intents.append(train_set['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otbQBTXNWtXZ"
   },
   "outputs": [],
   "source": [
    "queries_train, queries_cv, intents_train, intents_cv = train_test_split( queries, \n",
    "                                                        intents, train_size=0.7, \n",
    "                                                        random_state=123, \n",
    "                                                        stratify=intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63Z7Y7sJP52L",
    "outputId": "75c99a78-455b-4251-d296-f61c6e5ac8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(intents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSz0rqQ6RhAb"
   },
   "outputs": [],
   "source": [
    "num_classes= len(lbl_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TOjE_oPQaK4"
   },
   "outputs": [],
   "source": [
    "intents_train = lbl_encoder.transform(intents_train)\n",
    "intents_cv = lbl_encoder.transform(intents_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD3SwKkVQ393"
   },
   "outputs": [],
   "source": [
    "vocab_size = 2500\n",
    "embedding_dim = 200\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBgrv_E1QcfB"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, lower=True, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(queries_train)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(queries_train)\n",
    "padded_train_sequences = pad_sequences(sequences, padding='post' ,truncating='post', maxlen=max_len)\n",
    "sequences = tokenizer.texts_to_sequences(queries_cv)\n",
    "padded_cv_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGA4qYRJr5l0"
   },
   "outputs": [],
   "source": [
    "glove_path='/content/drive/MyDrive/Colab Notebooks/models/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o54_Dt_5rnzo"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "with open(glove_path) as gfile:\n",
    "    for line in gfile:\n",
    "        values = line.split()\n",
    "        word, vectors = values[0], np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXOKsaL9xGAw"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHVmT4PFRK1q",
    "outputId": "e28e467f-935f-451d-9f82-04f6d3279815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 200)           500000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                1170      \n",
      "=================================================================\n",
      "Total params: 514,034\n",
      "Trainable params: 14,034\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len, \n",
    "                    mask_zero=True, weights=[embedding_matrix], trainable=False))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcqG2BRmHUMm",
    "outputId": "c30407fe-0b60-41ff-82b6-39b64158c502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 200)           500000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                29824     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 18)                306       \n",
      "=================================================================\n",
      "Total params: 530,658\n",
      "Trainable params: 530,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len, \n",
    "                    mask_zero=True, weights=[embedding_matrix], trainable=True))\n",
    "model.add(LSTM(32, activation='relu', recurrent_dropout=0.2, dropout=0.2))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmeL4-a3RLYK",
    "outputId": "28c0cd8b-1eeb-42d9-8555-fe637faed2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 - 6s - loss: 2.8663 - accuracy: 0.0746 - val_loss: 2.7940 - val_accuracy: 0.2037\n",
      "Epoch 2/20\n",
      "20/20 - 3s - loss: 2.7073 - accuracy: 0.2190 - val_loss: 2.5634 - val_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "20/20 - 3s - loss: 2.4006 - accuracy: 0.3270 - val_loss: 2.1737 - val_accuracy: 0.4630\n",
      "Epoch 4/20\n",
      "20/20 - 3s - loss: 1.9807 - accuracy: 0.4127 - val_loss: 1.6839 - val_accuracy: 0.6185\n",
      "Epoch 5/20\n",
      "20/20 - 3s - loss: 1.6150 - accuracy: 0.5127 - val_loss: 1.2901 - val_accuracy: 0.7037\n",
      "Epoch 6/20\n",
      "20/20 - 3s - loss: 1.3225 - accuracy: 0.5984 - val_loss: 1.0380 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "20/20 - 3s - loss: 1.0633 - accuracy: 0.7095 - val_loss: 0.8006 - val_accuracy: 0.8407\n",
      "Epoch 8/20\n",
      "20/20 - 3s - loss: 0.9236 - accuracy: 0.7317 - val_loss: 0.6442 - val_accuracy: 0.9259\n",
      "Epoch 9/20\n",
      "20/20 - 3s - loss: 0.7866 - accuracy: 0.7619 - val_loss: 0.4834 - val_accuracy: 0.9370\n",
      "Epoch 10/20\n",
      "20/20 - 3s - loss: 0.6953 - accuracy: 0.7937 - val_loss: 0.4148 - val_accuracy: 0.9481\n",
      "Epoch 11/20\n",
      "20/20 - 3s - loss: 0.5957 - accuracy: 0.8254 - val_loss: 0.3459 - val_accuracy: 0.9370\n",
      "Epoch 12/20\n",
      "20/20 - 3s - loss: 0.5581 - accuracy: 0.8365 - val_loss: 0.2721 - val_accuracy: 0.9556\n",
      "Epoch 13/20\n",
      "20/20 - 3s - loss: 0.4863 - accuracy: 0.8492 - val_loss: 0.2409 - val_accuracy: 0.9519\n",
      "Epoch 14/20\n",
      "20/20 - 3s - loss: 0.4046 - accuracy: 0.8857 - val_loss: 0.2157 - val_accuracy: 0.9556\n",
      "Epoch 15/20\n",
      "20/20 - 3s - loss: 0.3849 - accuracy: 0.8968 - val_loss: 0.1959 - val_accuracy: 0.9630\n",
      "Epoch 16/20\n",
      "20/20 - 3s - loss: 0.3496 - accuracy: 0.9079 - val_loss: 0.1918 - val_accuracy: 0.9556\n",
      "Epoch 17/20\n",
      "20/20 - 3s - loss: 0.3192 - accuracy: 0.9032 - val_loss: 0.1571 - val_accuracy: 0.9630\n",
      "Epoch 18/20\n",
      "20/20 - 3s - loss: 0.2956 - accuracy: 0.9143 - val_loss: 0.1702 - val_accuracy: 0.9630\n",
      "Epoch 19/20\n",
      "20/20 - 3s - loss: 0.3182 - accuracy: 0.9095 - val_loss: 0.1350 - val_accuracy: 0.9704\n",
      "Epoch 20/20\n",
      "20/20 - 3s - loss: 0.2477 - accuracy: 0.9397 - val_loss: 0.1233 - val_accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(padded_train_sequences, intents_train, epochs=epochs\n",
    "                    , validation_data=(padded_cv_sequences, intents_cv)\n",
    "                    , verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9IQEvfpU6nG"
   },
   "outputs": [],
   "source": [
    "inputs = [\"what are the tests available for covid?\", \"bye\", \n",
    "          \"after how much time do I see the symptoms?\", \"That's great.\",\n",
    "          \"how do i protect myself?\", \"what is covid-19?\",\n",
    "          \"ok. what are the vaccines available?\", \n",
    "          \"i am looking for vaccination. i need help\",\n",
    "          \"how many people have suffered?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsWA26RBfVch",
    "outputId": "329a5366-9cb4-4336-f67b-897d9974239c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the tests available for covid?  -  covid_tests  -  0.9923597\n",
      "bye  -  bye  -  1.0\n",
      "after how much time do I see the symptoms?  -  development_period  -  0.9616318\n",
      "That's great.  -  thanks  -  0.99854016\n",
      "how do i protect myself?  -  protection  -  0.999724\n",
      "what is covid-19?  -  definition_covid  -  0.7742823\n",
      "ok. what are the vaccines available?  -  covid_vaccine  -  0.991459\n",
      "i am looking for vaccination. i need help  -  vaccination_slot  -  0.9740002\n",
      "how many people have suffered?  -  risk_people  -  0.9580922\n"
     ]
    }
   ],
   "source": [
    "for inp in inputs:\n",
    "    result = model.predict(pad_sequences(tokenizer.texts_to_sequences([inp]), \n",
    "                                            padding='post' ,truncating='post', \n",
    "                                         maxlen=max_len))\n",
    "    tag = lbl_encoder.inverse_transform([np.argmax(result)])[0]\n",
    "    print(inp,\" - \",tag,\" - \",result[0][np.argmax(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX1TmEIWU3Ud",
    "outputId": "16611076-71f7-4656-efa5-527fa3bea79e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the tests available for covid?  -  covid_tests  -  0.98211676\n",
      "bye  -  bye  -  0.9862748\n",
      "after how much time do I see the symptoms?  -  development_period  -  0.99999905\n",
      "That's great.  -  thanks  -  0.984144\n",
      "how do i protect myself?  -  protection  -  0.9787177\n",
      "what is covid-19?  -  definition_covid  -  0.6995017\n",
      "ok. what are the vaccines available?  -  covid_vaccine  -  0.99892527\n",
      "i am looking for vaccination. i need help  -  vaccination_slot  -  0.924329\n",
      "how many people have suffered?  -  covid_numbers  -  0.38376588\n"
     ]
    }
   ],
   "source": [
    "for inp in inputs:\n",
    "    result = model.predict(pad_sequences(tokenizer.texts_to_sequences([inp]), \n",
    "                                            padding='post' ,truncating='post', \n",
    "                                         maxlen=max_len))\n",
    "    tag = lbl_encoder.inverse_transform([np.argmax(result)])[0]\n",
    "    print(inp,\" - \",tag,\" - \",result[0][np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_training_tfModels",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
