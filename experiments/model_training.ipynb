{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bJWutAIcnoc"
   },
   "source": [
    "### Pre-requisite installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnMWN_FG8QFH",
    "outputId": "c6b5be1b-0833-4f06-e81a-30deb0ed65b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyYqZbyJRw0f"
   },
   "source": [
    "### Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kFWgMuXxT725"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wy-c29HEOlNI"
   },
   "outputs": [],
   "source": [
    "# For randomization and re-producability of results\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0wvecCQOlKS"
   },
   "outputs": [],
   "source": [
    "run_results=pd.DataFrame(columns=['Classifier', 'Mean Fit Time(s)', 'Mean Test Time(s)', \n",
    "                'Mean Train Score', 'Mean CV Score', 'Best Train Score','Test Score','F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOXW0O08hLHG"
   },
   "outputs": [],
   "source": [
    "# Using Glove embeddings\n",
    "embeddings_size=100\n",
    "glove_path='/content/drive/MyDrive/Colab Notebooks/models/glove.6B.%dd.txt'%embeddings_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgS2b3x2hRga"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "with open(glove_path) as gfile:\n",
    "    for line in gfile:\n",
    "        values = line.split()\n",
    "        word, vectors = values[0], np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTKaFOk3DUoN"
   },
   "outputs": [],
   "source": [
    "file_path = '/content/drive/MyDrive/Colab Notebooks/VICCI/data/generated_train_data.json'\n",
    "training_data = None\n",
    "with open(file_path, 'r') as file:\n",
    "    training_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjgJ0aQ5Oqkv"
   },
   "outputs": [],
   "source": [
    "queries, intents = [], []\n",
    "for train_set in training_data:\n",
    "    for query in train_set['query']:\n",
    "        queries.append(query)\n",
    "        intents.append(train_set['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdMQimxocSa0",
    "outputId": "4dc5bd95-5cc7-4c3a-b6fe-47f8a0094dbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 900)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data shape\n",
    "len(queries), len(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXnXcdeVseIa"
   },
   "outputs": [],
   "source": [
    "queries_train, queries_test, intents_train, intents_test = train_test_split( queries, \n",
    "                        intents, train_size=0.7, random_state=123, stratify=intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYeEcPWGh64p",
    "outputId": "b63214a5-1f6b-4381-b6ba-ad4a04dc51b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 270, 630, 270)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test set shape\n",
    "len(queries_train), len(queries_test), len(intents_train), len(intents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_C4RCpCOqhs"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1S8tG8KZPf45"
   },
   "outputs": [],
   "source": [
    "# We don't want to exclude stopwords as questions in chat are short and crisp and \n",
    "# words like \"what\" and \"not\" carry lot of weightage, but word_tokenizer treats the \n",
    "# sentence ending punctuations as separate tokens which have to be removed\n",
    "tfidf = TfidfVectorizer(max_features=600, encoding='latin-1', sublinear_tf=True, lowercase=True,\n",
    "                        tokenizer=word_tokenize, ngram_range=(1,2), \n",
    "                        stop_words=list(punctuation), token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BD68egzQ4vI",
    "outputId": "6e9e8269-2b58-42d9-d3e5-813597164f2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='latin-1',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=600,\n",
       "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words=['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*',\n",
       "                            '+', ',', '-', '.', '/', ':', ';', '<', '=', '>',\n",
       "                            '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', ...],\n",
       "                strip_accents=None, sublinear_tf=True, token_pattern=None,\n",
       "                tokenizer=<function word_tokenize at 0x7f0733ace200>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(queries_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93yXgmn6xH9x"
   },
   "outputs": [],
   "source": [
    "tfidf_dict = dict(zip(tfidf.get_feature_names(), list(tfidf.idf_)))\n",
    "tfidf_feat = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqFqb8_2hdly"
   },
   "outputs": [],
   "source": [
    "# We have to calculate the tf-Idf weighted average of the glove embeddings\n",
    "tfidf_weighted_glove_train = []\n",
    "for query in queries_train:\n",
    "    tokens = [tokn.lower() for tokn in word_tokenize(query) if tokn not in list(punctuation)]\n",
    "    query_vec = np.zeros(embeddings_size)\n",
    "    weight_sum = 0\n",
    "    for tokn in tokens:\n",
    "        if tokn in embeddings_index and tokn in tfidf_dict:\n",
    "            vec = embeddings_index[tokn]\n",
    "            # the tf-Idf score of a word in query is pumped up based on the ratio of its\n",
    "            # count in the query to the total query length  \n",
    "            score = tfidf_dict[tokn]*((tokens.count(tokn)/len(tokens))+1)\n",
    "            query_vec += (vec * score)\n",
    "            weight_sum += score\n",
    "        else:\n",
    "            # print(tokn)\n",
    "            pass\n",
    "    \n",
    "    if weight_sum != 0:\n",
    "        query_vec /= weight_sum\n",
    "    tfidf_weighted_glove_train.append(query_vec)\n",
    "tfidf_weighted_glove_train = np.array(tfidf_weighted_glove_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFG0XrIW1RiF"
   },
   "outputs": [],
   "source": [
    "# Similar vectorization for the test data\n",
    "tfidf_weighted_glove_test = []\n",
    "for query in queries_test:\n",
    "    tokens = [tokn.lower() for tokn in word_tokenize(query) if tokn not in list(punctuation)]\n",
    "    query_vec = np.zeros(embeddings_size)\n",
    "    weight_sum = 0\n",
    "    for tokn in tokens:\n",
    "        if tokn in embeddings_index and tokn in tfidf_dict:\n",
    "            vec = embeddings_index[tokn]\n",
    "            score = tfidf_dict[tokn]*((tokens.count(tokn)/len(tokens))+1)\n",
    "            query_vec += (vec * score)\n",
    "            weight_sum += score\n",
    "        else:\n",
    "            # print(tokn)\n",
    "            pass\n",
    "    \n",
    "    if weight_sum != 0:\n",
    "        query_vec /= weight_sum\n",
    "    tfidf_weighted_glove_test.append(query_vec)\n",
    "tfidf_weighted_glove_test = np.array(tfidf_weighted_glove_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjsrVP5RinjK",
    "outputId": "2a2049fd-0a69-4139-d55e-75d6025a73a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total feature length after conactenating both Tf-Idf and Weighted Glove\n",
    "len(tfidf_feat)+tfidf_weighted_glove_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTL9mhDZQ4sj"
   },
   "outputs": [],
   "source": [
    "X_train = np.hstack((tfidf.transform(queries_train).todense(), tfidf_weighted_glove_train))\n",
    "X_test = np.hstack((tfidf.transform(queries_test).todense(), tfidf_weighted_glove_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REGnkxdrkYkr",
    "outputId": "07ddb602-e9f6-4561-848e-e466c567ddb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((630, 700), (270, 700))"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dx8RMNBEQZxk",
    "outputId": "97ac9891-7976-406c-b345-9f685a5f20c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbencoder = LabelEncoder()\n",
    "lbencoder.fit(intents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYrnlSc-8wcE"
   },
   "outputs": [],
   "source": [
    "Y_train = lbencoder.transform(intents_train)\n",
    "Y_test = lbencoder.transform(intents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5e_aWemQ4pu"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UpcaH2cV70N"
   },
   "outputs": [],
   "source": [
    "def classifier_analyzer(classifier, params):\n",
    "    ss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=123)\n",
    "    # we are explicitly passing StratifiedShuffleSplit because we want the CV data to\n",
    "    # shuffles in each split which is not the default behaviour of GridSearchCV \n",
    "    gsCV = GridSearchCV(classifier, params, scoring='accuracy', n_jobs=-1, refit=True, \n",
    "                                    cv=ss, return_train_score=True)\n",
    "    gscv_result = gsCV.fit(X_train, Y_train).cv_results_\n",
    "    print(\"Mean fit time : %.3fs\" % gscv_result['mean_fit_time'].mean())\n",
    "    print(\"Mean test time : %.3fs\" % gscv_result['mean_score_time'].mean())\n",
    "    print(\"Mean train score : %.3f\" % gscv_result['mean_train_score'].mean())\n",
    "    print(\"Mean CV score : %.3f\" % gscv_result['mean_test_score'].mean())\n",
    "    \n",
    "    # Get the train score on the best estimator\n",
    "    print(\"Best Train Score : %.3f\" % accuracy_score(Y_train, gsCV.predict(X_train)))\n",
    "\n",
    "    # Get the test score on the best estimator\n",
    "    Y_pred = gsCV.predict(X_test)\n",
    "    print(\"Best Test Score  : %.3f\" % accuracy_score(Y_test, Y_pred))\n",
    "    \n",
    "    print(\"Best params : \", gsCV.best_params_)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYttIUQmV7u1",
    "outputId": "1b893d26-bc85-4e52-839f-439ea6ad26ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 5.798s\n",
      "Mean test time : 0.001s\n",
      "Mean train score : 0.987\n",
      "Mean CV score : 0.940\n",
      "Best Train Score : 0.990\n",
      "Best Test Score  : 0.978\n",
      "Best params :  {'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=123, n_jobs=-1)\n",
    "# not all the combination of penalty and solver will be compatible so we define\n",
    "# a list of params dict. First we fix the solver param, then go to fix C\n",
    "lr_params = [{'penalty' : ['l2'], \n",
    "              'solver':['newton-cg', 'sag', 'lbfgs'] }, \n",
    "             {'penalty' : ['elasticnet'], \n",
    "              'solver':['saga'],\n",
    "              'l1_ratio':[0, 0.25, 0.5, 0.75, 1]}]\n",
    "Y_pred = classifier_analyzer(lr_clf, lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWmVWhX6aZ-M",
    "outputId": "07ff0cc7-2147-4078-dd09-cfd980ff7668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 1.065s\n",
      "Mean test time : 0.002s\n",
      "Mean train score : 0.960\n",
      "Mean CV score : 0.906\n",
      "Best Train Score : 0.990\n",
      "Best Test Score  : 0.978\n",
      "Best params :  {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=123, n_jobs=-1)\n",
    "\n",
    "lr_params = [{'penalty' : ['l2'], \n",
    "              'solver':['newton-cg'],\n",
    "              'C': [0.01, 0.1, 1, 10, 100, 500] } ]\n",
    "              \n",
    "Y_pred = classifier_analyzer(lr_clf, lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mPRbY-Prr9W",
    "outputId": "290afddf-eabb-4662-e38d-4e198b879065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       1.00      1.00      1.00        15\n",
      "       covid_tests       1.00      1.00      1.00        15\n",
      "   covid_treatment       0.88      1.00      0.94        15\n",
      "     covid_vaccine       1.00      1.00      1.00        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.87      0.87      0.87        15\n",
      "development_period       1.00      1.00      1.00        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       1.00      1.00      1.00        15\n",
      "  longterm_effects       1.00      0.87      0.93        15\n",
      "     post_symptoms       0.88      1.00      0.94        15\n",
      "        protection       1.00      1.00      1.00        15\n",
      "       risk_people       1.00      1.00      1.00        15\n",
      "            spread       1.00      1.00      1.00        15\n",
      "          symptoms       1.00      0.87      0.93        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.98       270\n",
      "         macro avg       0.98      0.98      0.98       270\n",
      "      weighted avg       0.98      0.98      0.98       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kDRD1pNpMUu"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['Logistic Reg', 1.065, 0.002, 0.960, \n",
    "                                       0.906, 0.990, 0.978, 0.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VjUmEY1auW7",
    "outputId": "3321a5d9-d41c-4762-9e90-b00174248b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 0.019s\n",
      "Mean test time : 0.141s\n",
      "Mean train score : 0.944\n",
      "Mean CV score : 0.882\n",
      "Best Train Score : 0.994\n",
      "Best Test Score  : 0.948\n",
      "Best params :  {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "\n",
    "knn_clf = KNeighborsClassifier( n_jobs=-1)\n",
    "knn_params = {'n_neighbors':[3,5,7,10,15], \n",
    "              'weights':['uniform','distance'], \n",
    "             'metric':['cosine','minkowski','euclidean']}\n",
    "\n",
    "Y_pred = classifier_analyzer(knn_clf, knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRZBQWrDx8Lp",
    "outputId": "01ba02fb-9435-4a8f-c5c1-8fe7c355bbd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       1.00      1.00      1.00        15\n",
      "       covid_tests       1.00      0.93      0.97        15\n",
      "   covid_treatment       0.82      0.93      0.87        15\n",
      "     covid_vaccine       0.88      0.93      0.90        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.83      0.67      0.74        15\n",
      "development_period       0.94      1.00      0.97        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       0.88      1.00      0.94        15\n",
      "  longterm_effects       1.00      0.87      0.93        15\n",
      "     post_symptoms       0.88      1.00      0.94        15\n",
      "        protection       1.00      0.93      0.97        15\n",
      "       risk_people       1.00      1.00      1.00        15\n",
      "            spread       1.00      1.00      1.00        15\n",
      "          symptoms       0.86      0.80      0.83        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.95       270\n",
      "         macro avg       0.95      0.95      0.95       270\n",
      "      weighted avg       0.95      0.95      0.95       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiJcw79cp76Z"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['kNN', 0.019, 0.141, 0.944, 0.882, \n",
    "                                       0.994, 0.948, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaHaGNOYbUfh",
    "outputId": "e4a56ec3-9ae4-4106-f1ed-f93bfce3128e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 0.327s\n",
      "Mean test time : 0.069s\n",
      "Mean train score : 0.517\n",
      "Mean CV score : 0.471\n",
      "Best Train Score : 0.992\n",
      "Best Test Score  : 0.974\n",
      "Best params :  {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# SVM \n",
    "\n",
    "svm_clf = SVC(random_state=123)\n",
    "svm_params = {'C':[0.001, 0.01, 0.1, 1, 10], \n",
    "              'kernel':['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "Y_pred = classifier_analyzer(svm_clf, svm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJgL6QGyyi1_",
    "outputId": "14cead6f-0b93-4e88-b979-15ac8fbe160e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       1.00      1.00      1.00        15\n",
      "       covid_tests       1.00      1.00      1.00        15\n",
      "   covid_treatment       0.83      1.00      0.91        15\n",
      "     covid_vaccine       1.00      1.00      1.00        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.86      0.80      0.83        15\n",
      "development_period       1.00      1.00      1.00        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       1.00      1.00      1.00        15\n",
      "  longterm_effects       1.00      0.87      0.93        15\n",
      "     post_symptoms       0.88      1.00      0.94        15\n",
      "        protection       1.00      1.00      1.00        15\n",
      "       risk_people       1.00      1.00      1.00        15\n",
      "            spread       1.00      1.00      1.00        15\n",
      "          symptoms       1.00      0.87      0.93        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.97       270\n",
      "         macro avg       0.98      0.97      0.97       270\n",
      "      weighted avg       0.98      0.97      0.97       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLhyU6bxqGob"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['SVM', 0.327, 0.069, 0.517, \n",
    "                                       0.471, 0.992, 0.974, 0.97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IAALT9Mbd1z",
    "outputId": "a24ee2f2-a1c3-4f6f-fad4-956f366d593c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 0.385s\n",
      "Mean test time : 0.001s\n",
      "Mean train score : 0.936\n",
      "Mean CV score : 0.882\n",
      "Best Train Score : 0.989\n",
      "Best Test Score  : 0.981\n",
      "Best params :  {'alpha': 0.01, 'epsilon': 0.01, 'loss': 'modified_huber', 'max_iter': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier \n",
    "\n",
    "sgd_clf = SGDClassifier(early_stopping=False, n_jobs=-1, random_state=123)\n",
    "\n",
    "sgd_params = {'loss': ['hinge', 'modified_huber'], \n",
    "              'penalty': ['l2', 'elasticnet'], \n",
    "              'max_iter': [100, 300, 500, 700],\n",
    "              'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1], \n",
    "              'epsilon': [0.01, 0.05, 0.1]}\n",
    "\n",
    "Y_pred = classifier_analyzer(sgd_clf, sgd_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWrUCdqwzfbw",
    "outputId": "a18a75bf-e007-451f-957d-58bad479ef1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       0.94      1.00      0.97        15\n",
      "       covid_tests       1.00      1.00      1.00        15\n",
      "   covid_treatment       0.88      1.00      0.94        15\n",
      "     covid_vaccine       1.00      1.00      1.00        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.93      0.87      0.90        15\n",
      "development_period       1.00      1.00      1.00        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       1.00      1.00      1.00        15\n",
      "  longterm_effects       1.00      0.87      0.93        15\n",
      "     post_symptoms       1.00      0.93      0.97        15\n",
      "        protection       1.00      1.00      1.00        15\n",
      "       risk_people       1.00      1.00      1.00        15\n",
      "            spread       0.94      1.00      0.97        15\n",
      "          symptoms       1.00      1.00      1.00        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.98       270\n",
      "         macro avg       0.98      0.98      0.98       270\n",
      "      weighted avg       0.98      0.98      0.98       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKSFZFmwqPdY"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['SGD Classifier', 0.385, 0.001, 0.936, \n",
    "                                       0.882, 0.989, 0.981, 0.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPvV2f5mcq9R",
    "outputId": "d3788e58-4b8f-4dc6-af6c-f22cb1765ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 19.716s\n",
      "Mean test time : 0.034s\n",
      "Mean train score : 0.996\n",
      "Mean CV score : 0.930\n",
      "Best Train Score : 0.994\n",
      "Best Test Score  : 0.959\n",
      "Best params :  {'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost \n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=123, n_jobs=-1)\n",
    "\n",
    "# First we fix the objective param then, others\n",
    "xgb_params = [{'objective': ['binary:logistic', 'binary:hinge', \n",
    "                            'multi:softprob','multi:softmax']\n",
    "              },{\n",
    "                  'objective' : ['multi:softmax'],\n",
    "                  'num_class' : [len(set(intents))]\n",
    "              }]\n",
    "\n",
    "Y_pred = classifier_analyzer(xgb_clf, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSs6DcJykCqh",
    "outputId": "d351d771-6a7b-499e-fc8e-a9df9d263510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 5.342s\n",
      "Mean test time : 0.017s\n",
      "Mean train score : 0.995\n",
      "Mean CV score : 0.917\n",
      "Best Train Score : 0.994\n",
      "Best Test Score  : 0.967\n",
      "Best params :  {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 60}\n",
      "Mean fit time : 5.342s\n",
      "Mean test time : 0.017s\n",
      "Mean train score : 0.995\n",
      "Mean CV score : 0.917\n",
      "Best Train Score : 0.994\n",
      "Best Test Score  : 0.967\n",
      "Best params :  {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(objective='binary:logistic', random_state=123, n_jobs=-1)\n",
    "\n",
    "# First we fix the objective param then, others\n",
    "xgb_params = {\n",
    "              'max_depth' : [3, 5, 7],\n",
    "              'n_estimators':[5,10,20,35,60],\n",
    "              'learning_rate' : [0.1, 0.2, 0.3, 0.5, 0.7]\n",
    "            }\n",
    "Y_pred = classifier_analyzer(xgb_clf, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwrNb2FK138P",
    "outputId": "b5ffe446-da58-4df2-fa91-5e24dab6f60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       0.94      1.00      0.97        15\n",
      "       covid_tests       1.00      1.00      1.00        15\n",
      "   covid_treatment       0.83      1.00      0.91        15\n",
      "     covid_vaccine       1.00      1.00      1.00        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.86      0.80      0.83        15\n",
      "development_period       1.00      1.00      1.00        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       1.00      1.00      1.00        15\n",
      "  longterm_effects       1.00      0.87      0.93        15\n",
      "     post_symptoms       0.88      1.00      0.94        15\n",
      "        protection       1.00      0.87      0.93        15\n",
      "       risk_people       0.94      1.00      0.97        15\n",
      "            spread       1.00      1.00      1.00        15\n",
      "          symptoms       1.00      0.87      0.93        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.97       270\n",
      "         macro avg       0.97      0.97      0.97       270\n",
      "      weighted avg       0.97      0.97      0.97       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPi_U0rLrESn"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['XGBoost', 5.342, 0.017, 0.995, 0.917, \n",
    "                                            0.994, 0.967, 0.97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H-CmNlCBH1K"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyCr7Ow2BMR3",
    "outputId": "9d508115-f6a6-4e01-c239-d92350ba07fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB cant take negative values \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK9IST-SBTKR"
   },
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYVazNrLbz5N",
    "outputId": "ffc6be07-dd17-47e3-9ff6-7df38bca04cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time : 0.006s\n",
      "Mean test time : 0.001s\n",
      "Mean train score : 0.967\n",
      "Mean CV score : 0.887\n",
      "Best Train Score : 0.984\n",
      "Best Test Score  : 0.930\n",
      "Best params :  {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# MultiNomial naive bayes\n",
    "\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_params = {'alpha': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]}\n",
    "Y_pred = classifier_analyzer(mnb_clf, mnb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nI8FvJwiB7qe",
    "outputId": "556ab6d9-6e30-4c8f-d86d-266f80c3a6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the best params : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               bye       1.00      1.00      1.00        15\n",
      "     covid_numbers       1.00      1.00      1.00        15\n",
      "       covid_tests       1.00      0.73      0.85        15\n",
      "   covid_treatment       0.76      0.87      0.81        15\n",
      "     covid_vaccine       0.93      0.93      0.93        15\n",
      " definition_corona       1.00      1.00      1.00        15\n",
      "  definition_covid       0.82      0.60      0.69        15\n",
      "development_period       0.88      1.00      0.94        15\n",
      "             greet       1.00      1.00      1.00        15\n",
      "             intro       1.00      1.00      1.00        15\n",
      "  longterm_effects       0.93      0.87      0.90        15\n",
      "     post_symptoms       0.94      1.00      0.97        15\n",
      "        protection       1.00      0.93      0.97        15\n",
      "       risk_people       0.93      0.93      0.93        15\n",
      "            spread       0.88      1.00      0.94        15\n",
      "          symptoms       0.72      0.87      0.79        15\n",
      "            thanks       1.00      1.00      1.00        15\n",
      "  vaccination_slot       1.00      1.00      1.00        15\n",
      "\n",
      "          accuracy                           0.93       270\n",
      "         macro avg       0.93      0.93      0.93       270\n",
      "      weighted avg       0.93      0.93      0.93       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for the best params : \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=lbencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h30-hQVhqf5W"
   },
   "outputs": [],
   "source": [
    "run_results.loc[run_results.shape[0]]=['MultiNomial NB', 0.006, 0.001, 0.967, \n",
    "                                                0.887, 0.984, 0.930, 0.93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "21C428sqGLP9",
    "outputId": "93b9b0f6-86e2-44e4-a620-c9d7153f4196"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Mean Fit Time(s)</th>\n",
       "      <th>Mean Test Time(s)</th>\n",
       "      <th>Mean Train Score</th>\n",
       "      <th>Mean CV Score</th>\n",
       "      <th>Best Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultiNomial NB</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5.342</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier  Mean Fit Time(s)  ...  Test Score  F1 Score\n",
       "5  MultiNomial NB             0.006  ...       0.930      0.93\n",
       "1             kNN             0.019  ...       0.948      0.95\n",
       "4         XGBoost             5.342  ...       0.967      0.97\n",
       "2             SVM             0.327  ...       0.974      0.97\n",
       "0    Logistic Reg             1.065  ...       0.978      0.98\n",
       "3  SGD Classifier             0.385  ...       0.981      0.98\n",
       "\n",
       "[6 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_results.sort_values(by=['Test Score', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIUsMxxJOpQt"
   },
   "outputs": [],
   "source": [
    "inputs = [\"what are the tests available for covid?\", \"bye\", \n",
    "          \"after how much time do I see the symptoms?\", \"That's great.\",\n",
    "          \"how do i protect myself?\", \"what is covid-19?\",\n",
    "          \"ok. what are the vaccines available?\", \n",
    "          \"i am looking for vaccination. i need help\",\n",
    "          \"how many people have suffered?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1hUw8bMP-QY",
    "outputId": "dff549e8-8d82-44c4-9408-14c1a08e61ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.01, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "              max_iter=100, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "              power_t=0.5, random_state=123, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(alpha=0.01, epsilon=0.01, loss='modified_huber', max_iter=100,\n",
    "                        penalty='l2', early_stopping=False, n_jobs=-1, \n",
    "                        random_state=123)\n",
    "sgd_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63BcrrYVR92S",
    "outputId": "70d4c932-c958-4cc3-d565-3f8fa0c1c59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the tests available for covid?  -  covid_tests  -  0.9027125161518191\n",
      "bye  -  bye  -  1.0\n",
      "after how much time do I see the symptoms?  -  development_period  -  1.0\n",
      "That's great.  -  thanks  -  1.0\n",
      "how do i protect myself?  -  protection  -  1.0\n",
      "what is covid-19?  -  definition_covid  -  0.5159454543520243\n",
      "ok. what are the vaccines available?  -  covid_vaccine  -  1.0\n",
      "i am looking for vaccination. i need help  -  vaccination_slot  -  1.0\n",
      "how many people have suffered?  -  covid_numbers  -  0.36272658171682653\n"
     ]
    }
   ],
   "source": [
    "for inp in inputs:\n",
    "    tokens = [tokn.lower() for tokn in word_tokenize(inp) if tokn not in list(punctuation)]\n",
    "    query_vec = np.zeros(embeddings_size)\n",
    "    weight_sum = 0\n",
    "    for tokn in tokens:\n",
    "        if tokn in embeddings_index and tokn in tfidf_dict:\n",
    "            vec = embeddings_index[tokn]\n",
    "            score = tfidf_dict[tokn]*((tokens.count(tokn)/len(tokens))+1)\n",
    "            query_vec += (vec * score)\n",
    "            weight_sum += score\n",
    "        else:\n",
    "            # print(tokn)\n",
    "            pass\n",
    "\n",
    "    if weight_sum != 0:\n",
    "        query_vec /= weight_sum\n",
    "\n",
    "    pred = sgd_clf.predict_proba(np.hstack((tfidf.transform([inp]).todense(), \n",
    "                                           query_vec.reshape(1,-1))))\n",
    "    tag = lbencoder.inverse_transform([pred.argmax()])[0]\n",
    "    print(inp,\" - \",tag,\" - \",pred[0][pred.argmax()])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
